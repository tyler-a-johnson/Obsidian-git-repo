---
date: 2024-08-06
tags: 
status: Incomplete
Relevant Questions: 
Relevant Notes:
  - https://ilearn.mq.edu.au/mod/folder/view.php?id=8255357
Relevant Links:
---
**Lecture Slides:**
[Lecture Week 3 html](Attachments/Lecture_Week_3.html)
[Lecture Week 3 ipynb](Attachments/Lecture_Week_3.ipynb)
[Lecture Slides html](Attachments/Lecture_Week_3.slides.html)

# Data Science methodology
<div style="float: left">
<a title="By Kenneth Jensen [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File%3ACRISP-DM_Process_Diagram.png"><img width="512" alt="CRISP-DM Process Diagram" src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/512px-CRISP-DM_Process_Diagram.png"/></a>
</div>
*Cross-Industry Standard Process for Data Mining (CRISP-DM)* is a standardised workflow for Data Mining/Data Science that attempts to lay out a methodology to follow in a project. It is in comparable to software development life cycle. 

- As a **methodology**, CRISP-DM includes descriptions of the typical phases of a project, the tasks involved with each phase, and an explanation of the relationships between these tasks.
- As a **process model**, CRISP-DM provides an overview of the data mining life cycle.

**CRISP-DM model is flexible and can be customised**
- Example 1: **Detecting money laundering**
	- This task mainly focus on data exploration and visualisation to uncover suspicious patterns in data
- Example 2: [AI-based animal recognition](https://siwalusoftware.com/)

## Methodology
- **Data Preparation** and **Modelling** are the core processes we're learning how to do in Python
- **Model Evaluation** how will you know if you've succeeded? Evaluation of the model with respect to business needs - are the predictions accurate enough to help the business?
- **Deployment** is this a one off analysis that generates a report or a model that will be used repeatedly in some kind of production environment? Does it need to be updated as new data becomes available?
- [7 Fundamental Steps to Complete a Data Analytics Project](https://blog.dataiku.com/2019/07/04/fundamental-steps-data-project-success)
## Data Understanding
- Collecting data
- Describing data
- Exploring data
- Verifying data quality

## Data Cleaning
 * Data Quality (validity, accuracy, completeness, consistency, uniformity)
 * The workflow 
     * Inspection (data profiling, visualizations, software packages)
     * Cleaning (irrelevant data, duplicates, type conver., syntax errors, 6 more)
     * Verifying
     * Reporting
[The Ultimate Guide to Data Cleaning](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4) from Toward Data Science.

