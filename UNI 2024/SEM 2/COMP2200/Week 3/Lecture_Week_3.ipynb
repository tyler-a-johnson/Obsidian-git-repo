{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# COMP2200/COMP6200: Data Science\n",
    "## Lecture Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "- Data Science methodology and workflow\n",
    "- Data understanding\n",
    "- Descriptive statistics\n",
    "- Start thinking about project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science methodology\n",
    "\n",
    "<div style=\"float: left\">\n",
    "<a title=\"By Kenneth Jensen [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File%3ACRISP-DM_Process_Diagram.png\"><img width=\"512\" alt=\"CRISP-DM Process Diagram\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/512px-CRISP-DM_Process_Diagram.png\"/></a>\n",
    "</div>\n",
    "\n",
    "Cross-Industry Standard Process for Data Mining (CRISP-DM) is a standardised workflow for Data Mining/Data Science that attempts to lay out a methodology to follow in a project. It is in comparable to software development life cycle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- As a **methodology**, CRISP-DM includes descriptions of the typical phases of a project, the tasks involved with each phase, and an explanation of the relationships between these tasks.\n",
    "- As a **process model**, CRISP-DM provides an overview of the data mining life cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CRISP-DM model is flexible and can be customised\n",
    "- Example 1: **Detecting money laundering**\n",
    "  This task mainly focus on data exploration and visualisation to uncover suspicious patterns in data\n",
    "- Example 2: [AI-based animal recognition](https://siwalusoftware.com/)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methodology\n",
    "\n",
    "- **Business Understanding** DS problems generally come out of some business need (or maybe from some scientific or humanities research goal).  So, understanding why the questions are being asked and how an answer might be used is important.\n",
    "- **Data Understanding** what data is available, what do the fields mean, what other data sources would we like to be able to access, assessing data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methodology\n",
    "\n",
    "- **Data Preparation** and **Modelling** are the core processes we're learning how to do in Python\n",
    "- **Model Evaluation** how will you know if you've succeeded? Evaluation of the model with respect to business needs - are the predictions accurate enough to help the business?\n",
    "- **Deployment** is this a one off analysis that generates a report or a model that will be used repeatedly in some kind of production environment? Does it need to be updated as new data becomes available?\n",
    "- [7 Fundamental Steps to Complete a Data Analytics Project](https://blog.dataiku.com/2019/07/04/fundamental-steps-data-project-success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Understanding\n",
    "- Collecting data\n",
    "- Describing data\n",
    "- Exploring data\n",
    "- Verifying data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Cleaning\n",
    "\n",
    " * Data Quality (validity, accuracy, completeness, consistency, uniformity)\n",
    " * The workflow \n",
    "     * Inspection (data profiling, visualizations, software packages)\n",
    "     * Cleaning (irrelevant data, duplicates, type conver., syntax errors, 6 more)\n",
    "     * Verifying\n",
    "     * Reporting\n",
    "\n",
    "[The Ultimate Guide to Data Cleaning](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4) from Toward Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Formats\n",
    "\n",
    "* Data comes from various systems or databases\n",
    "* Often dumped in some easy to generate format: CSV, JSON, XML\n",
    "* Sometimes reading data not intended for re-use: text, audio/video metadata\n",
    "* A few file formats specific to structured data interchange: HDF5, Pickle, YAML\n",
    "\n",
    "- [How to read most commonly used data formats...](https://www.analyticsvidhya.com/blog/2017/03/read-commonly-used-formats-using-python/)\n",
    "- [Data serialisation](https://docs.python-guide.org/scenarios/serialization/)\n",
    "- [Reading 15 most common file formats used in Data Science](https://www.weirdgeek.com/2018/12/common-file-formats-used-in-data-science/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "It is a study of data analysis to describe, show or summarise data in a meaningful way.\n",
    "\n",
    "It involves the calculation of various measures such as the **measure of center**, **the measure of variability**, **percentiles**, and also the **construction of tables and graphs**.\n",
    "\n",
    "One of the first things we can do with a new data set is to explore it and see what the main characteristics are. To do this we can look at e.g.:\n",
    "\n",
    "- Types of data\n",
    "- size and shape of the data\n",
    "- range of values in columns\n",
    "- are there missing values\n",
    "- how are values distributed: mean, median, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of data\n",
    "\n",
    "### Numerical and categorical data\n",
    "\n",
    "- **Categorical data**: non-numerical information such as gender, race, religion, marital status, etc.\n",
    "- **Numerical data**: measurement or count such as height, weight, salary, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working example\n",
    "\n",
    "### [Python Statistics Fundamentals: How to Describe Your Data](https://realpython.com/python-statistics/)\n",
    "\n",
    "### [Data science tutorial - Exploratory Data Analysis](https://github.com/rasbt/data-science-tutorial)\n",
    "\n",
    "### Exploring [Melbourne house prices](https://www.kaggle.com/anthonypino/melbourne-housing-market#Melbourne_housing_FULL.csv) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles/MELBOURNE_HOUSE_PRICES_LESS.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "df = pd.read_csv('files/MELBOURNE_HOUSE_PRICES_LESS.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# checking dataframe shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# checking dataframe info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure of center for house prices\n",
    "house_prices = df['Price']\n",
    "house_prices.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# checking length of series\n",
    "len(house_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# counting number of Null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the Null values in dataframe \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "clean_df = df.dropna()\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# getting mean, median and standard deviation on the clean dataset\n",
    "# In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values.\n",
    "#A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, \n",
    "#while a high standard deviation indicates that the values are spread out over a wider range.\n",
    "mean_price = clean_df['Price'].mean()\n",
    "median_price = clean_df['Price'].median()\n",
    "std_dev_price = clean_df['Price'].std()\n",
    "print(\"mean price of house: \", mean_price)\n",
    "print(\"median price of house: \", median_price)\n",
    "print(\"standard deviation in price: \", std_dev_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns #Seaborn is a Python data visualization library based on matplotlib\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10,8)) #Width, height in inches.\n",
    "sns.boxplot(x='Price', data=clean_df, orient=\"h\") #https://pythonbasics.org/seaborn-boxplot/  orient“v” | “h”, optional Orientation of the plot (vertical or horizontal). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# checking price for different types of house\n",
    "plt.figure(figsize=(15,11))\n",
    "sns.boxplot(x='Type', y='Price', data=df, orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Exploring region-wise\n",
    "regions = clean_df['Regionname']\n",
    "print(\"Types of regions: \", len(set(regions)))\n",
    "\n",
    "plt.figure(figsize=(15,11))\n",
    "chart = sns.countplot(x='Regionname', data=clean_df) #Show the counts of observations in each categorical bin using bars.\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=30) #rotation of the lables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skewed Distributions\n",
    "\n",
    "When counting frequencies it is quite common to have many data points for a certain range of values and much less for the rest of the values. When this happens we say the distribution is not symmetric but skewed. The data distribution can be either positively skewed or negatively skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Positively skewed data\n",
    "# Source: https://www.stefanfiott.com/machine-learning/descriptive-statistics-tutorial/\n",
    "student_ages = pd.Series([15,19,18,14,13,\n",
    "                          27,16,65,15,31,\n",
    "                          22,15,24,22,51,\n",
    "                          24,20,45,22,33,\n",
    "                          24,27,18,66,15,\n",
    "                          18,39,10,30,13,\n",
    "                          19,28,53,28,65,\n",
    "                          30,20,21,20,18,\n",
    "                          20,23,18,41,52,\n",
    "                          75,19,63,14,18],\n",
    "                         name=\"Student Ages\")\n",
    "sns.distplot(student_ages, bins=10, kde=False); #depicts the variation in the data distribution, bins is the argument for matplotlib hist()\n",
    "#kde: Whether to plot a gaussian kernel density estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Negatively skewed data #pip install seaborn --upgrade\n",
    "# Source: https://www.stefanfiott.com/machine-learning/descriptive-statistics-tutorial/\n",
    "# Data for Age at Death of Australian Males in 2012. Ref: https://stats.stackexchange.com/a/122853\n",
    "deaths_per_age = {1:565, 5:116, 10:69, 15:78, 20:319, 25:501, 30:633, 35:655, 40:848, 45:1226, 50:1633, \n",
    "                  55:2459, 60:3375, 65:4669, 70:6152, 75:7436, 80:9526, 85:12619, 90:12455, 95:7113, 100:2104, 110:241}\n",
    "sns.histplot(bins=len(list(deaths_per_age.keys())), x=list(deaths_per_age.keys()), weights=list(deaths_per_age.values()))\n",
    "plt.title(\"Age at Death of Australian Males in 2012\")\n",
    "plt.ylabel(\"No. of Deaths\")\n",
    "plt.xlabel(\"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More on this\n",
    "[Practical Machine Learning Project in Python on House Prices Data](https://www.hackerearth.com/practice/machine-learning/machine-learning-projects/python-project/tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outliers\n",
    "\n",
    "<div style=\"float: left\">\n",
    "    <img src=\"https://miro.medium.com/max/2400/1*TbUF_HTQ6jOhO8EoPnmekQ.jpeg\" alt=\"Outlier Detection\" width=\"600\" height=\"500\">\n",
    "</div>\n",
    "\n",
    "In statistics, an **outlier** is an observation point that is distant from other observations.\n",
    "\n",
    "Outliers can have many causes, including:\n",
    "    - measurement or input error\n",
    "    - data corruption\n",
    "    - true outlier observation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we need to detect outliers\n",
    "\n",
    "- The temptation to start building models on the given data, often ignores data exploration and analysing outliers.\n",
    "- Outliers can impact the results of our analysis and statistical modeling in a drastic way.\n",
    "\n",
    "<div style=\"float: center\">\n",
    "    <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/02/impact-of-outliers.png\" alt=\"Outlier Detection\" width=\"600\" height=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outliers \n",
    "\n",
    "*\"Outliers are not necessarily a bad thing. These are just observations that are not following the same pattern as the other ones. But it can be the case that an outlier is very interesting. For example, if in a biological experiment, a rat is not dead whereas all others are, then it would be very interesting to understand why. This could lead to new scientific discoveries.  So, it is important to detect outliers.\"*\n",
    "                                                           - Pierre Lafaye de Micheaux, Author and Statistician\n",
    "\n",
    "[5 Ways to Find Outliers in Your Data](https://statisticsbyjim.com/basics/outliers/#:~:text=Outliers%20are%20data%20points%20that,findings%20or%20distort%20real%20results.)\n",
    "\n",
    "[Guidelines for Removing and Handling Outliers in Data](https://statisticsbyjim.com/basics/remove-outliers/)\n",
    "\n",
    "\n",
    "[Handling outliers](https://www.rapidinsight.com/handle-outliers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Privacy\n",
    "\n",
    "*\"Nothing about an individual should be learnable from the database that cannot be learned without access to the database.\"* — Tore Dalenius\n",
    "\n",
    "- [Myki privacy de-railed](https://about.unimelb.edu.au/newsroom/news/2019/august/myki-privacy-de-railed-travellers-movements-and-identities-at-risk-by-public-release-of-anonymised-data)\n",
    "- [Data Privacy in the age of Big Data](https://towardsdatascience.com/data-privacy-in-the-age-of-big-data-c28405e15508)\n",
    "- [Rethinking Data Privacy: The Impact of Machine Learning](https://medium.com/luminovo/data-privacy-in-machine-learning-a-technical-deep-dive-f7f0365b1d60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data privacy: Tips for Data Scientists\n",
    "\n",
    "- Source: [Navigating the Data Privacy Maze: Tips for Data Scientists](https://towardsdatascience.com/navigating-the-data-privacy-maze-tips-for-data-scientists-c2f784969f29)\n",
    "\n",
    "- Slides: [Navigating the Data Privacy Maze: Tips for Data Scientists](https://github.com/pydataedinburgh/meetups/blob/master/meetup-2018-07-25/katherine-jarmal-privacy-maze.pdf)\n",
    "\n",
    "- [Australia Privacy Principles](https://www.oaic.gov.au/privacy/australian-privacy-principles/read-the-australian-privacy-principles)\n",
    "<div style=\"float: center\">\n",
    "    <img src=\"https://miro.medium.com/max/1043/1*_Ck2F4L45SytTjar47YVdA.png\" alt=\"Data privacy\" width=\"600\" height=\"500\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
