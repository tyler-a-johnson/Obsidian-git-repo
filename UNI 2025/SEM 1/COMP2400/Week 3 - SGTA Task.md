---
date: 2025-03-08
tags: 
status: Incomplete
Relevant Questions: 
Relevant Notes: 
Relevant Links:
---
Recommend 150 words each

1. *Johnson (2021) develops and discusses the ‘proxy problem’ in their account of algorithmic bias. Please characterise the problem and give an example of its occurrence.* 
The 'proxy problem', as described by Gabbrielle M. Johnson (2021) arises when innocuous or seemingly unrelated attributes in algorithmic decision making serve as 'proxies' for socially sensitive attributes such as race, gender, and religion. Even when these sensitive attributes are deliberately removed from the dataset, the machine learning algorithm can still infer these traits indirectly through correlated proxy features. This happens as machine learning models infer patterns in data that may not be immediately apparent to researchers and engineers, leading to algorithmic biases that reflect real world biases against marginalized groups.

2. *What exactly is the ‘value neutrality thesis’ as discussed by Fazelpour and Danks (2021)? Does it accurately capture the relationship between algorithmic decision- making and the reality of our socially and politically shaped lifeworld?*



3. According to Fazelpour and Danks (2021), fairness through unawareness has remained a largely unsuccessful strategy to mitigate algorithmic bias. Which reasons do they provide in support of their view? Do you agree with their assessment? If yes, why? If not, why not?